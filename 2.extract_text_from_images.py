import os
from pathlib import Path
import json
import base64
from openai import OpenAI
import time
from dotenv import load_dotenv

load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

def encode_image_to_base64(image_path):
    """Chuyá»ƒn áº£nh thÃ nh base64"""
    with open(image_path, "rb") as image_file:
        return base64.b64encode(image_file.read()).decode('utf-8')

def ocr_with_openai(image_path, detail="low", model="gpt-4o"):
    """ OCR sá»­ dá»¥ng OpenAI Vision API - ÄÃƒ KHáº®C PHá»¤C Váº¤N Äá»€ Bá»Š Cáº®T """
    try:
        base64_image = encode_image_to_base64(image_path)

        # PROMPT Tá»I Æ¯U - Ngáº¯n gá»n, rÃµ rÃ ng
        prompt = """
YÃŠU Cáº¦U Äá»ŠNH Dáº NG:
- Giá»¯ nguyÃªn Ä‘á»‹nh dáº¡ng gá»‘c (xuá»‘ng dÃ²ng, thá»¥t lá», dáº¥u tiáº¿ng Viá»‡t)
- Bao gá»“m má»i kÃ½ hiá»‡u, sá»‘, chá»¯ cÃ¡i, cÃ´ng thá»©c
- KhÃ´ng bá» sÃ³t báº¥t ká»³ pháº§n nÃ o
- Tuyá»‡t Ä‘á»‘i khÃ´ng Ä‘Æ°á»£c bao vÄƒn báº£n trong dáº¥u ``` hoáº·c báº¥t ká»³ dáº¡ng markdown code block nÃ o
QUY Táº®C CHO CÃ‚U TRáº®C NGHIá»†M:
- Náº¿u cÃ¢u há»i cÃ³ cÃ¡c Ä‘Ã¡p Ã¡n A, B, C, D thÃ¬ báº¯t buá»™c:
+ Má»—i Ä‘Ã¡p Ã¡n pháº£i xuá»‘ng dÃ²ng riÃªng
+ KhÃ´ng Ä‘Æ°á»£c Ä‘á»ƒ A, B, C, D náº±m trÃªn cÃ¹ng má»™t dÃ²ng
VÃ­ dá»¥ Ä‘Ãºng:
A. (1) vÃ  (2)
B. (2) vÃ  (3)
C. (3) vÃ  (1)
D. cáº£ (1), (2) vÃ  (3)
YÃŠU Cáº¦U Äáº¶C BIá»†T CHO HÃ“A â€“ SINH â€“ TOÃN:
- Nháº­n dáº¡ng Ä‘Ãºng chá»‰ sá»‘ dÆ°á»›i (Hâ‚‚O â†’ H_2O), sá»‘ mÅ© (Naâº â†’ Na^+), mÅ© hÃ³a trá»‹, chá»‰ sá»‘ phÃ¢n tá»­
- Nháº­n Ä‘Ãºng mÅ© vÃ  chá»‰ sá»‘ cá»§a phÆ°Æ¡ng trÃ¬nh hÃ³a há»c, phÆ°Æ¡ng trÃ¬nh toÃ¡n há»c, cÃ´ng thá»©c váº­t lÃ½
- Giá»¯ nguyÃªn mÅ©i tÃªn pháº£n á»©ng (â†’, â†”, â‡Œ, â†“, â†‘)
- Náº¿u OCR nháº§m chi â†’ chá»‰ cáº§n phá»¥c há»“i Ä‘Ãºng tá»« ngá»¯ dá»±a trÃªn ngá»¯ cáº£nh
CHá»ˆ TRáº¢ Vá»€ VÄ‚N Báº¢N OCR:
- KhÃ´ng thÃªm lá»i giáº£i thÃ­ch
- KhÃ´ng thÃªm ghi chÃº
- KhÃ´ng Ä‘Æ°á»£c chÃ¨n vÃ o code block
INPUT:
(Pháº§n vÄƒn báº£n OCR tá»« áº£nh)
OUTPUT:
Chá»‰ tráº£ vá» vÄƒn báº£n Ä‘Ã£ chuáº©n hÃ³a theo Ä‘Ãºng Ä‘á»‹nh dáº¡ng trÃªn
"""


        # Tá»± Ä‘á»™ng chá»n max_tokens dá»±a trÃªn model
        if model == "gpt-4o-mini":
            max_tokens = 16000
        else:
            max_tokens = 16000

        response = client.chat.completions.create(
            model=model,
            messages=[
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "text",
                            "text": prompt
                        },
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/jpeg;base64,{base64_image}",
                                "detail": detail
                            }
                        }
                    ]
                }
            ],
            max_tokens=max_tokens,
            temperature=0,
        )

        extracted_text = response.choices[0].message.content
        usage = response.usage
        finish_reason = response.choices[0].finish_reason

        # Cáº¢NH BÃO Náº¾U Bá»Š Cáº®T
        if finish_reason == 'length':
            print(f" âš ï¸ Cáº¢NH BÃO: Output bá»‹ cáº¯t do vÆ°á»£t max_tokens!")
            print(f" â†’ VÄƒn báº£n cÃ³ thá»ƒ THIáº¾U! CÃ¢n nháº¯c tÄƒng max_tokens hoáº·c dÃ¹ng gpt-4o")

        return {
            'success': True,
            'text': extracted_text,
            'model': model,
            'detail': detail,
            'usage': {
                'prompt_tokens': usage.prompt_tokens,
                'completion_tokens': usage.completion_tokens,
                'total_tokens': usage.total_tokens
            },
            'finish_reason': finish_reason,
            'truncated': finish_reason == 'length'
        }

    except Exception as e:
        return {
            'success': False,
            'error': str(e),
            'text': ''
        }

def process_exam_with_openai(folder_path, detail="low", model="gpt-4o", delay=0.5, output_name='openai_ocr_results'):
    """Xá»­ lÃ½ hÃ ng loáº¡t áº£nh vá»›i OpenAI Vision API"""
    print("ğŸš€ Báº®T Äáº¦U Xá»¬ LÃ Vá»šI OPENAI VISION API")
    print(f" Model: {model}")
    print(f" Detail: {detail}")
    print("="*80)

    image_extensions = {'.png', '.jpg', '.jpeg', '.bmp', '.tiff'}
    folder = Path(folder_path)
    image_files = sorted([f for f in folder.iterdir() if f.is_file() and f.suffix.lower() in image_extensions])

    print(f"\nğŸ“š TÃ¬m tháº¥y {len(image_files)} áº£nh\n")

    results = {}
    total_tokens = 0
    success_count = 0
    truncated_count = 0

    for idx, image_file in enumerate(image_files, 1):
        print(f"[{idx}/{len(image_files)}] ğŸ“„ {image_file.name}")

        result = ocr_with_openai(image_file, detail=detail, model=model)

        if result['success']:
            success_count += 1
            usage = result['usage']
            total_tokens += usage['total_tokens']

            if result.get('truncated', False):
                truncated_count += 1

            results[image_file.name] = {
                'text': result['text'],
                'model': result['model'],
                'detail': result['detail'],
                'usage': usage,
                'finish_reason': result['finish_reason'],
                'truncated': result.get('truncated', False)
            }

            print(f" âœ… ThÃ nh cÃ´ng!")
            print(f" - Tokens: {usage['total_tokens']} (prompt: {usage['prompt_tokens']}, completion: {usage['completion_tokens']})")
            print(f" - Finish reason: {result['finish_reason']}")

            text_preview = result['text'][:150].replace('\n', ' ')
            print(f" - Preview: {text_preview}...")

        else:
            print(f" âŒ Lá»—i: {result['error']}")
            results[image_file.name] = {
                'error': result['error'],
                'text': ''
            }

        print()
        if idx < len(image_files):
            time.sleep(delay)

    print("\n" + "="*80)
    print("ğŸ’° CHI PHÃ Æ¯á»šC TÃNH")
    print("="*80)

    if model == "gpt-4o":
        input_price = 2.50 / 1_000_000
        output_price = 10.00 / 1_000_000
    elif model == "gpt-4o-mini":
        input_price = 0.15 / 1_000_000
        output_price = 0.60 / 1_000_000
    else:
        input_price = output_price = 0

    total_input_tokens = sum(r['usage']['prompt_tokens'] for r in results.values() if 'usage' in r)
    total_output_tokens = sum(r['usage']['completion_tokens'] for r in results.values() if 'usage' in r)

    input_cost = total_input_tokens * input_price
    output_cost = total_output_tokens * output_price
    total_cost = input_cost + output_cost

    print(f"Model: {model}")
    print(f"Detail: {detail}")
    print(f"\nTokens:")
    print(f" - Input tokens: {total_input_tokens:,}")
    print(f" - Output tokens: {total_output_tokens:,}")
    print(f" - Total tokens: {total_tokens:,}")

    print(f"\nChi phÃ­:")
    print(f" - Input cost: ${input_cost:.4f}")
    print(f" - Output cost: ${output_cost:.4f}")
    print(f" - TOTAL COST: ${total_cost:.4f} (â‰ˆ {total_cost * 25000:,.0f} VNÄ)")
    print(f" - Cost/image: ${total_cost/len(image_files):.4f}")

    print(f"\nThá»‘ng kÃª:")
    print(f" - Tá»•ng áº£nh: {len(image_files)}")
    print(f" - ThÃ nh cÃ´ng: {success_count}")
    print(f" - Lá»—i: {len(image_files) - success_count}")

    if truncated_count > 0:
        print(f"\nâš ï¸ Cáº¢NH BÃO:")
        print(f" - Sá»‘ áº£nh bá»‹ cáº¯t output: {truncated_count}/{len(image_files)}")
        print(f" - Khuyáº¿n nghá»‹: Chuyá»ƒn sang gpt-4o hoáº·c tÄƒng max_tokens")

    output_json = folder / f'{output_name}.json'

    save_data = {
        'metadata': {
            'model': model,
            'detail': detail,
            'total_images': len(image_files),
            'success_count': success_count,
            'truncated_count': truncated_count,
            'total_cost_usd': total_cost,
            'total_cost_vnd': total_cost * 25000,
            'total_tokens': total_tokens,
            'input_tokens': total_input_tokens,
            'output_tokens': total_output_tokens
        },
        'results': results
    }

    with open(output_json, 'w', encoding='utf-8') as f:
        json.dump(save_data, f, ensure_ascii=False, indent=2)

    output_txt = folder / f'{output_name}.txt'

    with open(output_txt, 'w', encoding='utf-8') as f:
        f.write(f"OPENAI VISION OCR RESULTS\n")
        f.write(f"Model: {model} | Detail: {detail}\n")
        f.write(f"Total Cost: ${total_cost:.4f} (â‰ˆ {total_cost * 25000:,.0f} VNÄ)\n")

        if truncated_count > 0:
            f.write(f"âš ï¸ WARNING: {truncated_count} images had truncated output\n")

        f.write(f"="*80 + "\n\n")

        for filename, data in results.items():
            f.write(f"{'='*80}\n")
            f.write(f"ğŸ“„ {filename}\n")

            if 'truncated' in data and data['truncated']:
                f.write(f"âš ï¸ OUTPUT Bá»Š Cáº®T - VÄ‚N Báº¢N CÃ“ THá»‚ THIáº¾U!\n")

            f.write(f"{'='*80}\n")

            if 'error' not in data:
                f.write(f"Tokens: {data['usage']['total_tokens']} | Finish: {data['finish_reason']}\n\n")
                f.write(data['text'])
            else:
                f.write(f"âŒ Lá»–I: {data['error']}")

            f.write(f"\n\n")

    print(f"\nğŸ“ Káº¿t quáº£ Ä‘Ã£ lÆ°u:")
    print(f" - JSON: {output_json}")
    print(f" - TXT: {output_txt}")
    print("="*80 + "\n")
    
    save_data["json_file"] = str(output_json)
    save_data["txt_file"] = str(output_txt)

    return save_data

if __name__ == "__main__":
    FOLDER_PATH = "data/input/img/hoa_test"
    results = process_exam_with_openai(
        folder_path=FOLDER_PATH,
        detail="high",
        model="gpt-4o-mini",
        delay=0.5,
        output_name='openai_ocr_low'
    )
